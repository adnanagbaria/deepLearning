{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNORW6gRmMc+iYJWpnBRxMg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adnanagbaria/deepLearning/blob/main/classification1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI Classification\n",
        "This file shows an example of building a classification model"
      ],
      "metadata": {
        "id": "p6OCSa9KGS2p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzHcIFK4GJI3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount to Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMifmF8-G8qP",
        "outputId": "46ab7eca-f468-43e9-ee75-deea8e1d097c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement load_dataset() using AI.\n",
        "\n",
        "AI query: implement a function for loading dataset and return dataset and dataLoader"
      ],
      "metadata": {
        "id": "0HWvNc9RMECE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: implement a function for loading dataset and return dataset and dataLoader\n",
        "\n",
        "def load_dataset(data_dir, batch_size=32):\n",
        "\n",
        "  # Define the transforms for the images\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "  ])\n",
        "\n",
        "  # Load the datasets\n",
        "  train_dataset = ImageFolder(os.path.join(data_dir, 'train'), transform=transform)\n",
        "  test_dataset = ImageFolder(os.path.join(data_dir, 'val'), transform=transform)\n",
        "\n",
        "  # Create the data loaders\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  return train_loader, test_loader\n"
      ],
      "metadata": {
        "id": "9GXdAtO_IvMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Implement a function to show dataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "def show_dataset(dataset, num_images=5):\n",
        "  # Get a batch of images and labels\n",
        "  images, labels = next(iter(dataloader))\n",
        "\n",
        "  # Show the images\n",
        "  for i in range(num_images):\n",
        "    plt.imshow(images[i].permute(1, 2, 0))\n",
        "    plt.title(f\"Label: {labels[i]}\")\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "jL_ivjReMXf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a function to initialize the ResNet50 model\n",
        "\n",
        "def initialize_model():\n",
        "  # Load the ResNet50 model\n",
        "  model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "\n",
        "  # Freeze the model parameters\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "  # Modify the final layer to have the correct number of outputs\n",
        "  num_features = model.fc.in_features\n",
        "  model.fc = nn.Linear(num_features, len(dataset.classes))\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "4ATlSI7bxnsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Write a function to train resnet50\n",
        "\n",
        "def train_model(model, dataloader, num_epochs=3):\n",
        "  # Define the loss function and optimizer\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model.to(device)\n",
        "\n",
        "  # Train the model\n",
        "  for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(dataloader):\n",
        "      # Move the images and labels to the device\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # Forward pass\n",
        "      outputs = model(images)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      # Backward pass\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print the progress\n",
        "      if i % 100 == 0:\n",
        "        print(f\"Epoch: {epoch+1}/{num_epochs}, Batch: {i+1}/{len(dataloader)}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "  # Save the model\n",
        "  torch.save(model.state_dict(), 'model.pt')\n",
        "\n"
      ],
      "metadata": {
        "id": "Anw7hj5JyWK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main\n",
        "Here we have the main code\n",
        "1. Load the dataset\n",
        "2. Show the dataset (some of them if needed)\n",
        "3. Initialize the model\n",
        "4. train the model"
      ],
      "metadata": {
        "id": "Oei39BpLNEd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = '/content/drive/MyDrive/Colab Notebooks/deepLearning/dataset/covid'"
      ],
      "metadata": {
        "id": "DJGYi91RNSuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Load the dataset of train and test\n",
        "\n",
        "train_loader, test_loader = load_dataset(dataset_dir)\n"
      ],
      "metadata": {
        "id": "xwm41tlL2xMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print the size of train dataset\n",
        "\n",
        "print(f\"Train dataset size: {len(train_loader.dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-Dd_vnS3nSF",
        "outputId": "8465215a-801f-466c-96eb-9947bb3bfcd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Initialize the model\n",
        "\n",
        "model = initialize_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN0zy33v3v_8",
        "outputId": "ebee81aa-3035-4e75-c142-f768b0099b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 101MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Train the model\n",
        "\n",
        "train_model(model, train_loader, num_epochs=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYOXy2SG34yl",
        "outputId": "8e16b80b-699d-4133-88e6-f5c8681ca876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/3, Batch: 1/3, Loss: 0.6805\n",
            "Epoch: 2/3, Batch: 1/3, Loss: 0.6241\n",
            "Epoch: 3/3, Batch: 1/3, Loss: 0.5471\n"
          ]
        }
      ]
    }
  ]
}